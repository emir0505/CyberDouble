{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b48682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перплексия дообученной модели (microsoft/phi-4-mini-instruct): 87.42\n",
      "Перплексия дообученной модели (C:\\Users\\emir\\models\\mymodel): 26.87\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Предполагаемые имена моделей и пути к данным\n",
    "base_model_name = \"microsoft/phi-4-mini-instruct\"  # Необученная модель\n",
    "fine_tuned_model_name = \"C:/users/emir/models/mymodel\"  # Замените на фактический путь к вашей дообученной модели\n",
    "data_path = \"path/to/personachat_holdout.jsonl\"  # Замените на путь к вашему файлу PersonaChat\n",
    "\n",
    "# Загрузка токенизатора (используем токенизатор базовой модели)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "\n",
    "# Функция для расчета перплексии на PersonaChat\n",
    "def calculate_perplexity_personachat(model, tokenizer, dataset, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Вычисляет перплексию для модели на датасете PersonaChat.\n",
    "\n",
    "    Args:\n",
    "        model: Модель для оценки (PyTorch модель).\n",
    "        tokenizer: Токенизатор для модели (Hugging Face Tokenizer).\n",
    "        dataset: Датасет PersonaChat (Hugging Face Dataset).\n",
    "        device: Устройство для вычислений (\"cuda\" или \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "        float: Перплексия.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    for dialog in dataset:\n",
    "        for turn in dialog[\"turns\"]:  # Предполагается, что у вас есть поле \"turns\"\n",
    "            text = turn[\"text\"]  # и \"text\" содержит реплику\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "            labels = inputs[\"input_ids\"]\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs, labels=labels)\n",
    "            loss = outputs.loss.item()\n",
    "            total_loss += loss * labels.size(1)\n",
    "            total_tokens += labels.size(1)\n",
    "\n",
    "    mean_loss = total_loss / total_tokens\n",
    "    perplexity = torch.exp(torch.tensor(mean_loss)).item()\n",
    "    return perplexity\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Загрузка датасета PersonaChat\n",
    "    holdout_dataset = load_dataset(\"json\", data_files=data_path, split=\"train\") # Или как у вас\n",
    "\n",
    "    # 1. Расчет перплексии для базовой модели\n",
    "    print(\"Загрузка базовой модели...\")\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(base_model_name).to(\"cuda\")\n",
    "    base_perplexity = calculate_perplexity_personachat(base_model, tokenizer, holdout_dataset)\n",
    "    print(f\"Перплексия базовой модели ({base_model_name}): {base_perplexity}\")\n",
    "    del base_model  # Освобождаем память\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # 2. Расчет перплексии для дообученной модели\n",
    "    print(\"Загрузка дообученной модели...\")\n",
    "    try:\n",
    "        fine_tuned_model = AutoModelForCausalLM.from_pretrained(fine_tuned_model_name).to(\"cuda\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке дообученной модели.  Убедитесь, что путь '{fine_tuned_model_name}' указан правильно, и модель там есть. Ошибка: {e}\")\n",
    "        exit()\n",
    "    fine_tuned_perplexity = calculate_perplexity_personachat(fine_tuned_model, tokenizer, holdout_dataset)\n",
    "    print(f\"Перплексия дообученной модели ({fine_tuned_model_name}): {fine_tuned_perplexity}\")\n",
    "    del fine_tuned_model #Освобождаем память\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
